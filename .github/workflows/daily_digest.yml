name: Daily News Digest

on:
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘
  schedule:
    # æ¯ä¸ªå·¥ä½œæ—¥ 22:20 UTC (16:20 CT / ç¾Žè‚¡æ”¶ç›˜åŽ)
    - cron: '20 22 * * 1-5'
    # æ¯ä¸ªå·¥ä½œæ—¥ 12:10 UTC (06:10 CT / ç›˜å‰)
    - cron: '10 12 * * 1-5'

jobs:
  generate-digest:
    runs-on: ubuntu-latest
    
    env:
      FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      SEC_USER_AGENT: ${{ secrets.SEC_USER_AGENT }}
      # åˆ‡æ¢ AI Provider: gemini æˆ– openai
      AI_PROVIDER: ${{ secrets.AI_PROVIDER || 'gemini' }}
      GEMINI_MODEL: gemini-2.0-flash
      OPENAI_MODEL: gpt-4o-mini
      OUTPUTS: markdown
      WATCHLIST_PATH: data/watchlist.yaml
      PROMPTS_DIR: data/prompts
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt

      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt

      - name: Create .env file
        run: |
          cd backend
          echo "FINNHUB_API_KEY=$FINNHUB_API_KEY" > .env
          echo "GEMINI_API_KEY=$GEMINI_API_KEY" >> .env
          echo "OPENAI_API_KEY=$OPENAI_API_KEY" >> .env
          echo "SEC_USER_AGENT=$SEC_USER_AGENT" >> .env
          echo "AI_PROVIDER=$AI_PROVIDER" >> .env
          echo "GEMINI_MODEL=$GEMINI_MODEL" >> .env
          echo "OPENAI_MODEL=$OPENAI_MODEL" >> .env
          echo "OUTPUTS=$OUTPUTS" >> .env
          echo "WATCHLIST_PATH=$WATCHLIST_PATH" >> .env
          echo "PROMPTS_DIR=$PROMPTS_DIR" >> .env
          echo "=== .env file created ==="
          echo "AI_PROVIDER: $AI_PROVIDER"
          echo "GEMINI_API_KEY length: ${#GEMINI_API_KEY}"
          echo "OPENAI_API_KEY length: ${#OPENAI_API_KEY}"
          echo "FINNHUB_API_KEY length: ${#FINNHUB_API_KEY}"

      - name: Copy data files
        run: |
          mkdir -p backend/data/prompts
          cp data/watchlist.yaml backend/data/watchlist.yaml
          cp -r data/prompts/* backend/data/prompts/
          echo "=== Data files copied ==="
          ls -la backend/data/
          ls -la backend/data/prompts/

      - name: Verify secrets
        run: |
          echo "=== Verifying Secrets ==="
          if [ -z "$GEMINI_API_KEY" ]; then
            echo "âŒ ERROR: GEMINI_API_KEY is empty!"
            echo "Please set the GEMINI_API_KEY secret in GitHub repository settings."
            exit 1
          else
            echo "âœ… GEMINI_API_KEY is set (length: ${#GEMINI_API_KEY})"
            echo "   Key prefix: ${GEMINI_API_KEY:0:8}..."
          fi
          if [ -z "$FINNHUB_API_KEY" ]; then
            echo "âš ï¸ WARNING: FINNHUB_API_KEY is empty"
          else
            echo "âœ… FINNHUB_API_KEY is set (length: ${#FINNHUB_API_KEY})"
          fi

      - name: Test Gemini API
        run: |
          cd backend
          echo "=== Testing Gemini API Connection ==="
          python -c "
          import os
          import sys
          
          # 1. æ£€æŸ¥çŽ¯å¢ƒå˜é‡
          api_key = os.environ.get('GEMINI_API_KEY', '')
          print(f'[1] API Key from env: {len(api_key)} chars')
          print(f'    Key prefix: {api_key[:8]}...' if api_key else '    No key')
          
          # 2. æ£€æŸ¥ pydantic settings
          print()
          print('[2] Testing pydantic-settings...')
          from app.config import settings
          print(f'    settings.ai_provider: {settings.ai_provider}')
          print(f'    settings.gemini_api_key: {len(settings.gemini_api_key)} chars')
          print(f'    settings.gemini_model: {settings.gemini_model}')
          
          # 3. æµ‹è¯• AI Provider å·¥åŽ‚
          print()
          print('[3] Testing AI Provider Factory...')
          try:
              from app.providers.factory import get_ai_provider
              provider = get_ai_provider()
              print(f'    âœ… Provider created: {provider.provider_name} / {provider.model_name}')
          except Exception as e:
              print(f'    âŒ Provider creation FAILED: {type(e).__name__}: {e}')
              import traceback
              traceback.print_exc()
              sys.exit(1)
          
          # 4. æµ‹è¯•å®žé™… API è°ƒç”¨
          print()
          print('[4] Testing actual Gemini API call...')
          try:
              from google import genai
              from google.genai import types
              client = genai.Client(api_key=settings.gemini_api_key)
              response = client.models.generate_content(
                  model=settings.gemini_model,
                  contents='Say hello in one word.',
                  config=types.GenerateContentConfig(max_output_tokens=10)
              )
              print(f'    âœ… Gemini API test SUCCESS: {response.text}')
          except Exception as e:
              print(f'    âŒ Gemini API test FAILED: {type(e).__name__}: {e}')
              import traceback
              traceback.print_exc()
              sys.exit(1)
          
          print()
          print('=== All tests passed! ===')
          "

      - name: Run daily digest pipeline
        run: |
          cd backend
          echo "=== Environment Check ==="
          python -c "
          import os
          from app.config import settings
          print(f'AI Provider: {settings.ai_provider}')
          print(f'Gemini Model: {settings.gemini_model}')
          print(f'Gemini API Key from settings: {bool(settings.gemini_api_key)}')
          print(f'Gemini API Key length from settings: {len(settings.gemini_api_key) if settings.gemini_api_key else 0}')
          print(f'Gemini API Key from env: {len(os.environ.get(\"GEMINI_API_KEY\", \"\"))}')
          print(f'Outputs: {settings.outputs}')
          print(f'Prompts dir: {settings.prompts_dir}')
          print(f'Watchlist path: {settings.watchlist_path}')
          
          # Check .env file
          import pathlib
          env_file = pathlib.Path('.env')
          if env_file.exists():
              content = env_file.read_text()
              lines = content.strip().split('\n')
              print(f'.env file exists with {len(lines)} lines')
              for line in lines:
                  if '=' in line:
                      key = line.split('=')[0]
                      val = line.split('=', 1)[1] if len(line.split('=', 1)) > 1 else ''
                      print(f'  {key}: {len(val)} chars')
          else:
              print('.env file not found!')
          "
          echo ""
          echo "=== Running pipeline ==="
          python -m app.cli --hours 24 --limit 5 --debug 2>&1 | tee pipeline.log
          echo ""
          echo "=== Pipeline completed ==="
          echo ""
          echo "=== Key log lines ==="
          grep -E "(AI provider|GeminiProvider|Starting AI|Analysis|success|failed|bullish|bearish|COMPLETED|Error|âŒ|âœ…|ðŸš€|Continuing without|provider created|Calling AI)" pipeline.log || echo "No matching patterns found"
          echo ""
          echo "=== Stats summary ==="
          grep -E "(Analyzed|Collected|Delivered|Stats)" pipeline.log | tail -20 || echo "No stats found"
          echo ""
          echo "=== Full AI-related logs ==="
          grep -i "ai\|gemini\|provider\|analysis\|neutral" pipeline.log | head -50 || echo "No AI logs found"

      - name: Upload digest as artifact
        uses: actions/upload-artifact@v4
        with:
          name: daily-digest-${{ github.run_number }}
          path: |
            backend/data/digests/*.md
            backend/data/digests/charts/*.png
            backend/pipeline.log
          retention-days: 30

      - name: Create summary
        run: |
          echo "## ðŸ“° Daily Digest Generated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Analysis Stats" >> $GITHUB_STEP_SUMMARY
          grep -E "Analyzed:" backend/pipeline.log >> $GITHUB_STEP_SUMMARY || echo "Stats not found" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Download the digest from **Artifacts** above." >> $GITHUB_STEP_SUMMARY
